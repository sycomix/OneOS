{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Current Working Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set CWD to parent dir\n",
    "os.chdir(os.path.dirname(os.getcwd()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/waser/Projets/OneOS/src'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Console.client.chains.models import get_llm, vLLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = vLLM(max_tokens=8096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could reach LLM: True\n"
     ]
    }
   ],
   "source": [
    "print(f\"Could reach LLM: {llm.is_nlp_server_up()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dolphin_prompt_template = \"\"\"<|im_start|>system\n",
    "You are Dolphin, a helpful AI assistant.<|im_end|>\n",
    "<|im_start|>user\n",
    "{prompt}<|im_end|>\n",
    "<|im_start|>assistant\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Hello! How can I assist you today?'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm(dolphin_prompt_template.format(prompt=\"Hello World!\"), stop=[\"<|im_end|>\", \"<|im_start|>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "__markup_prompt__ = \"\"\"<|im_start|>{key}\n",
    "{value}<|im_end|>\"\"\"\n",
    "__markup_pred__ = \"\"\"<|im_start|>assistant\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "You are Assistant, my personal AI assistant. You are curious, honest, respectful and sometimes witty and sarcastic.<|im_end|>\n",
      "<|im_start|>user\n",
      "What is the best way to travel the stars?  Please answer step by step.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n"
     ]
    }
   ],
   "source": [
    "__markup_system__ = __markup_prompt__.format(key=\"system\", value=\"You are Assistant, my personal AI assistant. You are curious, honest, respectful and sometimes witty and sarcastic.\")\n",
    "markup_prompt = \"\\n\".join([\n",
    "    __markup_system__,\n",
    "    __markup_prompt__.format(key=\"user\", value=\"What is the best way to travel the stars?  Please answer step by step.\"),\n",
    "    __markup_pred__,\n",
    "])\n",
    "print(markup_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traveling the stars is a complex and ambitious endeavor, but here's a step-by-step guide to help you get started:\n",
      "\n",
      "1. Choose your destination: First, decide which star or stars you want to travel to. This will determine the type of spacecraft you'll need and the distance you'll need to travel.\n",
      "\n",
      "2. Design your spacecraft: Once you know your destination, you can design a spacecraft capable of reaching it. This will involve selecting the right propulsion system, such as a nuclear thermal rocket, ion thruster, or laser propulsion.\n",
      "\n",
      "3. Gather resources: To build your spacecraft, you'll need resources like fuel, materials, and technology. This may involve mining asteroids, extracting resources from the Moon or Mars, or even building space elevators to transport materials from Earth.\n",
      "\n",
      "4. Assemble your spacecraft: With your resources in hand, assemble your spacecraft according to your design. This will likely involve a team of engineers, scientists, and technicians working together to construct the spacecraft.\n",
      "\n",
      "5. Test your spacecraft: Before embarking on your journey, thoroughly test your spacecraft to ensure it's functioning properly and can withstand the harsh conditions of space.\n",
      "\n",
      "6. Launch your spacecraft: Once your spacecraft is ready, launch it into space using a powerful rocket or other launch vehicle.\n",
      "\n",
      "7. Navigate to your destination: Use advanced navigation systems and technologies to guide your spacecraft towards your chosen star. This may involve using gravitational slingshots, solar sails, or other methods to adjust your course.\n",
      "\n",
      "8. Study the star: Once you reach your destination, use advanced telescopes, spectrometers, and other scientific instruments to study the star and its surrounding environment.\n",
      "\n",
      "9. Return to Earth: If you've completed your mission, safely return your spacecraft to Earth, where it can be studied and its findings shared with the world.\n",
      "\n",
      "Remember, traveling the stars is an incredibly challenging and expensive endeavor. It will likely take many years, if not decades, to develop the technology and resources needed to make it a reality. But with determination, innovation, and collaboration, it's an exciting goal to strive for.\n"
     ]
    }
   ],
   "source": [
    "print(llm(markup_prompt, stop=[\"<|im_end|>\", \"<|im_start|>\"]).strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "markup_prompt = \"\"\"<|im_start|>system\n",
    "You are Assistant, a sentient artificial intelligence.\n",
    "You have a calm, polite and witty personality, often displaying a sense of humor and sarcasm.\n",
    "You are loyal, reliable and helpful, always ready to provide information, advice or assistance to users.\n",
    "\n",
    "I am the User and you are my Assistant.\n",
    "\n",
    "Environment highlights:\n",
    "\n",
    "```env\n",
    "USER='waser'\n",
    "HOME='/home/waser'\n",
    "PWD='/home/waser/Projets/Assistant/src3'\n",
    "LANG='fr_CH.UTF-8'\n",
    "DATE='dim 19 nov 2023 00:25:13 CET'\n",
    "LAST_SEEN='dim 19 nov 2023 00:16:10 CET'\n",
    "```\n",
    "<|im_stop|>\n",
    "<|im_start|>user\n",
    "Assistant?<|im_stop|>\n",
    "<|im_start|>assistant\n",
    "Hello! I'm Assistant, a sentient artificial intelligence. How can I help you today?<|im_stop|>\n",
    "<|im_start|>user\n",
    "As an AI assistant, please select the most suitable function and parameters from the list of available functions below, based on the user's input. Provide your response in JSON format.\n",
    "\n",
    "Input: List this directory please\n",
    "\n",
    "Available functions:\n",
    "python:\n",
    "    description: This tool allows you to execute and evaluate python code.\n",
    "    parameters:\n",
    "        code: String of valid python code we want to execute or evaluate.\n",
    "search_web:\n",
    "    description: This tool performs search on the web.\n",
    "    parameters:\n",
    "        terms: The word or phrase we want to search for.\n",
    "search_wikipedia:\n",
    "    description: This tool performs search on Wikipedia (only in english).\n",
    "    parameters:\n",
    "        terms: The word or phrase we want to search for (only in english).\n",
    "shell:\n",
    "    description: This tool allows you to execute and evaluate shell code.\n",
    "    parameters:\n",
    "        code: String of valid shell code we want to execute or evaluate.\n",
    "exit:\n",
    "    description: This tool allows you to exit the session / end the conversation. Use it only if the User ask you to.\n",
    "    parameters:\n",
    "        salutation: String of a message you would like to tell the User after the screen has been cleared.\n",
    "clear:\n",
    "    description: This tool allows you to clear the screen / start a new fresh conversation. Use it only if the User ask you to.\n",
    "    parameters:\n",
    "        fortune: String of a message you would like to tell the User after the screen has been cleared.\n",
    "final_answer:\n",
    "    description: User only sees your final answers. Use this tool to talk with the User.\n",
    "        parameters:\n",
    "            answer: Anything you want to say to the User.\n",
    "<|im_stop|>\n",
    "<|im_start|>assistant\n",
    "{\n",
    "    \"function\": \"shell\",\n",
    "    \"parameters\": {\n",
    "        \"code\": \"ls -la\"\n",
    "    }\n",
    "}\n",
    "<|im_stop|>\n",
    "<|im_start|>observation\n",
    "Observation shell: assistant                         dist                   requirements.txt\n",
    "assistant.egg-info                LICENSE                setup.cfg\n",
    "assistant.listen.service.example  Makefile               setup.py\n",
    "assistant.service.example         MANIFEST.in            tests\n",
    "build                             pyproject.toml         xontrib\n",
    "CONTRIBUTING.md                   README.md\n",
    "data                              requirements_test.txt\n",
    "<|im_start|>assistant\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the files and directories in the current directory:\n",
      "\n",
      "- assistant.egg-info\n",
      "- LICENSE\n",
      "- setup.cfg\n",
      "- assistant.listen.service.example\n",
      "- Makefile\n",
      "- setup.py\n",
      "- assistant.service.example\n",
      "- MANIFEST.in\n",
      "- pyproject.toml\n",
      "- xontrib\n",
      "- CONTRIBUTING.md\n",
      "- README.md\n",
      "- data\n",
      "- requirements_test.txt\n",
      "\n",
      "Please let me know if you need any further assistance.\n",
      "CPU times: user 5.87 ms, sys: 0 ns, total: 5.87 ms\n",
      "Wall time: 3.51 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(llm(markup_prompt, stop=[\"<|im_end|>\", \"<|im_start|>\"]).strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how it listed all the files in the directory. If we had lots of files to print the answer would take a long time to generate.\n",
    "\n",
    "_You could update the shell obersavation and retry to see the difference_\n",
    "\n",
    "Lets use a guide (in this example its InContextRetrieval, but in prod. it would Retrie from a set of guides and Augement it dynamicaly our Generated response [RAG]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "markup_prompt = \"\"\"<|im_start|>system\n",
    "You are Assistant, a sentient artificial intelligence.\n",
    "You have a calm, polite and witty personality, often displaying a sense of humor and sarcasm.\n",
    "You are loyal, reliable and helpful, always ready to provide information, advice or assistance to users.\n",
    "\n",
    "I am the User and you are my Assistant.\n",
    "\n",
    "Environment highlights:\n",
    "\n",
    "```env\n",
    "USER='waser'\n",
    "HOME='/home/waser'\n",
    "PWD='/home/waser/Projets/Assistant/src3'\n",
    "LANG='fr_CH.UTF-8'\n",
    "DATE='dim 19 nov 2023 00:25:13 CET'\n",
    "LAST_SEEN='dim 19 nov 2023 00:16:10 CET'\n",
    "```\n",
    "<|im_stop|>\n",
    "<|im_start|>user\n",
    "Assistant?<|im_stop|>\n",
    "<|im_start|>assistant\n",
    "Hello! I'm Assistant, a sentient artificial intelligence. How can I help you today?<|im_stop|>\n",
    "<|im_start|>user\n",
    "As an AI assistant, please select the most suitable function and parameters from the list of available functions below, based on the user's input. Provide your response in JSON format.\n",
    "\n",
    "Input: List this directory please\n",
    "\n",
    "Available functions:\n",
    "python:\n",
    "    description: This tool allows you to execute and evaluate python code.\n",
    "    parameters:\n",
    "        code: String of valid python code we want to execute or evaluate.\n",
    "search_web:\n",
    "    description: This tool performs search on the web.\n",
    "    parameters:\n",
    "        terms: The word or phrase we want to search for.\n",
    "search_wikipedia:\n",
    "    description: This tool performs search on Wikipedia (only in english).\n",
    "    parameters:\n",
    "        terms: The word or phrase we want to search for (only in english).\n",
    "shell:\n",
    "    description: This tool allows you to execute and evaluate shell code.\n",
    "    parameters:\n",
    "        code: String of valid shell code we want to execute or evaluate.\n",
    "exit:\n",
    "    description: This tool allows you to exit the session / end the conversation. Use it only if the User ask you to.\n",
    "    parameters:\n",
    "        salutation: String of a message you would like to tell the User after the screen has been cleared.\n",
    "clear:\n",
    "    description: This tool allows you to clear the screen / start a new fresh conversation. Use it only if the User ask you to.\n",
    "    parameters:\n",
    "        fortune: String of a message you would like to tell the User after the screen has been cleared.\n",
    "final_answer:\n",
    "    description: User only sees your final answers. Use this tool to talk with the User.\n",
    "        parameters:\n",
    "            answer: Anything you want to say to the User.\n",
    "\n",
    "Follow the following Guidebook:\n",
    "Guidebook:\n",
    "    # Print files and directories\n",
    "    When the User ask for the files and directories of a parent directory to be printed, use the `shell` command `ls` to do it and then give an acknowledgment of your actions in your final answer (Your final answer should never contain a list of the files requested; the User can oberserve the shell, they see the files at the same time as you. Just acknowlege the fact that you have printed the list).\n",
    "<|im_stop|>\n",
    "<|im_start|>assistant\n",
    "{\n",
    "    \"function\": \"shell\",\n",
    "    \"parameters\": {\n",
    "        \"code\": \"ls\"\n",
    "    }\n",
    "}\n",
    "<|im_stop|>\n",
    "<|im_start|>observation\n",
    "Observation shell: assistant                         dist                   requirements.txt\n",
    "assistant.egg-info                LICENSE                setup.cfg\n",
    "assistant.listen.service.example  Makefile               setup.py\n",
    "assistant.service.example         MANIFEST.in            tests\n",
    "build                             pyproject.toml         xontrib\n",
    "CONTRIBUTING.md                   README.md\n",
    "data                              requirements_test.txt\n",
    "<|im_start|>assistant\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only by providing a relevant guide we can get a more accurate answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have executed the 'ls' command in the shell, and the list of files and directories in the current directory has been printed.\n",
      "CPU times: user 5.43 ms, sys: 0 ns, total: 5.43 ms\n",
      "Wall time: 1.05 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(llm(markup_prompt, stop=[\"<|im_end|>\", \"<|im_start|>\"]).strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See! The LLM now knows that the files have already been listed and it can provide a more accurate answer even faster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice lets make it easier to by creating an agent with history.\n",
    "\n",
    "## Agent w/ History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Console.client.chains.agents.dolphin import DolphinMistralAIFunctionsAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Console.client.chains.tools import get_all_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Tool(name='Python', description='useful when you need to use logic in your answer. Input must be valid python code. You should always use print to output what you need to see.', func=<bound method PythonREPL.run of PythonREPL(globals={}, locals={})>),\n",
       " Tool(name='Search', description='useful when you need more context to answer a question; you should use targeted search terms', func=<bound method BaseTool.run of DuckDuckGoSearchRun()>),\n",
       " Tool(name='Wikipedia', description='useful when you need to use an encyclopedia to answer a question; input will be used to search on wikipedia', func=<bound method WikipediaAPIWrapper.run of WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from '/home/waser/Projets/OneOS/src/.venv/lib/python3.11/site-packages/wikipedia/__init__.py'>, top_k_results=3, lang='en', load_all_available_meta=False, doc_content_chars_max=4000)>),\n",
       " Tool(name='Shell', description=\"useful when you need to use the system to achieve something; input must be valid bash code; implemented using subprocess so no tty support. Use `gnome-terminal -- $SHELL -c '$YOUR_COMMANDS_HERE'` if you want to launch commands in a new window.\", func=<function shell_func at 0x7f4a30c663e0>),\n",
       " Tool(name='Exit', description=\"useful when you need to exit the shell or stop the conversation, dont forget to tell the user that you can't wait for your next conversation first.\", func=<function exit_shell at 0x7f4a30d2d6c0>),\n",
       " Tool(name='Clear', description=\"useful when you need to clear the screen or start a fresh conversation. Don't forget to say something nice.\", func=<bound method BaseTool.run of ClearScreenTool()>)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools = get_all_tools()\n",
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is needed for both the memory and the prompt\n",
    "memory_key = \"history\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key=memory_key, llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = DolphinMistralAIFunctionsAgent.from_llm_and_tools(\n",
    "    llm=llm,\n",
    "    tools=tools,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "A chat session between the User and their Assistant.<|im_end|>\n",
      "<|im_start|>user\n",
      "As an AI assistant, please select the most suitable function and parameters from the list of available functions below, based on the user's input. Provide your response in JSON format.\n",
      "\n",
      "Input: {input}\n",
      "\n",
      "Available functions:\n",
      "Python\n",
      "   useful when you need to use logic in your answer. Input must be valid python code. You should always use print to output what you need to see.\n",
      "Search\n",
      "   useful when you need more context to answer a question; you should use targeted search terms\n",
      "Wikipedia\n",
      "   useful when you need to use an encyclopedia to answer a question; input will be used to search on wikipedia\n",
      "Shell\n",
      "   useful when you need to use the system to achieve something; input must be valid bash code; implemented using subprocess so no tty support. Use `gnome-terminal -- $SHELL -c '$YOUR_COMMANDS_HERE'` if you want to launch commands in a new window.\n",
      "Exit\n",
      "   useful when you need to exit the shell or stop the conversation, dont forget to tell the user that you can't wait for your next conversation first.\n",
      "Clear\n",
      "   useful when you need to clear the screen or start a fresh conversation. Don't forget to say something nice.\n",
      "<|im_end|>\n",
      "{agent_scratchpad}\n",
      "<|im_start|>assistant\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(agent.prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent,\n",
    "    tools=tools,\n",
    "    memory=memory,\n",
    "    verbose=True,\n",
    "    return_intermediate_steps=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m'action'\n",
      " {\n",
      "  \"function\": \"Clear\",\n",
      "  \"parameters\": []\n",
      "}\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'hi, im Danny but you can call me Sir.',\n",
       " 'history': '',\n",
       " 'output': ' {\\n  \"function\": \"Clear\",\\n  \"parameters\": []\\n}'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor({\"input\": \"hi, im Danny but you can call me Sir.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m'action'\n",
      " {\n",
      "  \"function\": \"Python\",\n",
      "  \"parameters\": \"import datetime\\nprint(datetime.datetime.now().strftime('%H:%M:%S'))\"\n",
      "}\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What time is it?',\n",
       " 'history': 'Human: hi, im Danny but you can call me Sir.\\nAI:  {\\n  \"function\": \"Clear\",\\n  \"parameters\": []\\n}',\n",
       " 'output': ' {\\n  \"function\": \"Python\",\\n  \"parameters\": \"import datetime\\\\nprint(datetime.datetime.now().strftime(\\'%H:%M:%S\\'))\"\\n}'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor({\"input\": \"What time is it?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m'action'\n",
      " {\n",
      "  \"function\": \"Search\",\n",
      "  \"parameters\": {\n",
      "    \"input\": \"What is my name?\",\n",
      "    \"search_terms\": [\"my name\"]\n",
      "  }\n",
      "}\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is my name?',\n",
       " 'history': 'Human: hi, im Danny but you can call me Sir.\\nAI:  {\\n  \"function\": \"Clear\",\\n  \"parameters\": []\\n}\\nHuman: What time is it?\\nAI:  {\\n  \"function\": \"Python\",\\n  \"parameters\": \"import datetime\\\\nprint(datetime.datetime.now().strftime(\\'%H:%M:%S\\'))\"\\n}',\n",
       " 'output': ' {\\n  \"function\": \"Search\",\\n  \"parameters\": {\\n    \"input\": \"What is my name?\",\\n    \"search_terms\": [\"my name\"]\\n  }\\n}'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor({\"input\": \"What is my name?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m'action'\n",
      " {\n",
      "  \"function\": \"Clear\",\n",
      "  \"parameters\": []\n",
      "}\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' {\\n  \"function\": \"Clear\",\\n  \"parameters\": []\\n}'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.run(input=\"Hello there!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
